{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ANLY580 Project1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required library\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import re\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of tweets:  12284\n"
     ]
    }
   ],
   "source": [
    "# Input data (Data in the dev directory)\n",
    "\n",
    "# Open Input.txt, read the file and save to variable named f\n",
    "f = open('./data/Dev/INPUT.txt').readlines()\n",
    "stop_words = set(stopwords.words('english'))\n",
    "num_of_tweets = 0\n",
    "lines = []\n",
    "\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "# Create preprocess_tweet function that preprocess the tweet by setting all the words to lower case and remove url\n",
    "def preprocess_tweet(tweet):\n",
    "    words = tweet.split(' ')\n",
    "    temp = []\n",
    "    for w in words:\n",
    "        s = w.lower()\n",
    "        if \"http\" in s or s in stop_words:\n",
    "            continue\n",
    "        else:\n",
    "            temp.append(s)\n",
    "    return \" \".join(temp)\n",
    "\n",
    "input_tuple = []\n",
    "input_tweets = []\n",
    "for line in f:\n",
    "    num_of_tweets = num_of_tweets+1\n",
    "    input_id = line.split('\\t',2)[0]\n",
    "    s = line.split('\\t',2)[2]\n",
    "    input_tuple.append((input_id,preprocess_tweet(s)))\n",
    "    input_tweets.append(preprocess_tweet(s))\n",
    "    \n",
    "print(\"Total number of tweets: \", len(input_tuple))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import WhitespaceTokenizer\n",
    "from nltk.tokenize import TweetTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of words white:  124923\n",
      "Total number of words tweet:  153822\n"
     ]
    }
   ],
   "source": [
    "##tokenize with different tokenizer\n",
    "white_tokens = WhitespaceTokenizer().tokenize(\" \".join(input_tweets))\n",
    "tweet_tokens = TweetTokenizer().tokenize(\" \".join(input_tweets))\n",
    "print(\"Total number of words white: \", len(white_tokens))\n",
    "print(\"Total number of words tweet: \", len(tweet_tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "##get the frequency\n",
    "from nltk.probability import ConditionalFreqDist\n",
    "from nltk.probability import FreqDist\n",
    "\n",
    "tweet_tokens = list(filter (lambda s:any([c.isalnum() for c in s]), tweet_tokens))\n",
    "white_tokens = list(filter (lambda s:any([c.isalnum() for c in s]), white_tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_white = FreqDist(white_tokens)\n",
    "freq_tweet = FreqDist(tweet_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trump :  710\n",
      "like :  464\n",
      "via :  377\n",
      "get :  356\n",
      "i'm :  297\n",
      "one :  295\n",
      "new :  292\n",
      "people :  292\n",
      "would :  260\n",
      "us :  247\n"
     ]
    }
   ],
   "source": [
    "#The total number of tokens corresponding to the top 10 most frequent words (types) in the vocabulary\n",
    "top10 = list(freq_white.most_common(10))\n",
    "for t in top10:\n",
    "    print(t[0],\": \",t[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avg words per tweet:  9.901497883425595\n",
      "avg chars per tweet:  77.4558775643113\n",
      "Avg chars of tokens:  6.790109348022692\n",
      "Std chars of tokens:  3.531759688124525\n",
      "Unique words:  38999\n",
      "Token/Type:  0.32063635616213104\n"
     ]
    }
   ],
   "source": [
    "input_tuple_tokens = []\n",
    "num_of_chars = 0\n",
    "lchars = []\n",
    "for tu in input_tuple:\n",
    "    tokens = WhitespaceTokenizer().tokenize(tu[1])\n",
    "    tokens = list(filter (lambda s:any([c.isalnum() for c in s]), tokens))\n",
    "    num_of_chars = num_of_chars + len(tu[1])\n",
    "    input_tuple_tokens.append((tu[0],tokens))\n",
    "    \n",
    "    \n",
    "print(\"avg words per tweet: \", len(white_tokens)/len(input_tweets))\n",
    "print(\"avg chars per tweet: \", num_of_chars/len(input_tweets))\n",
    "\n",
    "for token in white_tokens:\n",
    "    lchars.append(len(token))\n",
    "\n",
    "print(\"Avg chars of tokens: \",np.mean(lchars))\n",
    "print(\"Std chars of tokens: \",np.std(lchars))\n",
    "\n",
    "print(\"Unique words: \", len(set(white_tokens)))\n",
    "print(\"Token/Type: \", len(set(white_tokens))/len(white_tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "##token log frequency plot\n",
    "from matplotlib import pyplot as plt\n",
    "top30 = list(freq_white.most_common(30))\n",
    "word30 = [t[0] for t in top30]\n",
    "log30 = [np.log(t[1]) for t in top30]\n",
    "plt.plot(word30,log30)\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distinct 2 grams words:  99809\n",
      "Distinct 3 grams words:  97937\n",
      "Distinct 4 grams words:  87533\n",
      "Distinct 5 grams words:  76017\n"
     ]
    }
   ],
   "source": [
    "from nltk import ngrams\n",
    "n_grams = {}\n",
    "\n",
    "for n in range(2,6):\n",
    "    d_n = {}\n",
    "    for t in input_tweets:\n",
    "        grams = ngrams(t.split(),n)\n",
    "        for g in grams:\n",
    "            if g in d_n:\n",
    "                d_n[g] = d_n[g]+1\n",
    "            else:\n",
    "                d_n[g] = 1\n",
    "    n_grams[n] = d_n\n",
    "    print(\"Distinct\",n,\"grams words: \",len(d_n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distinct 2 grams chars:  4597\n",
      "Distinct 3 grams chars:  29535\n",
      "Distinct 4 grams chars:  102820\n",
      "Distinct 5 grams chars:  226659\n",
      "Distinct 6 grams chars:  363957\n",
      "Distinct 7 grams chars:  476797\n"
     ]
    }
   ],
   "source": [
    "n_grams_chars = {}\n",
    "for n in range(2,8):\n",
    "    d_char = {}\n",
    "    for b in input_tweets:\n",
    "        grams = [b[i:i+n] for i in range(len(b)-n+1)]\n",
    "        for g in grams:\n",
    "            if g in d_char:\n",
    "                d_char[g] = d_char[g]+1\n",
    "            else:\n",
    "                d_char[g] = 1\n",
    "    n_grams_chars[n] = d_char\n",
    "    print(\"Distinct\",n,\"grams chars: \",len(d_char))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Combine all the input.\n",
    "dev = open('./data/Gold/dev.txt').readlines()\n",
    "devtest = open('./data/Gold/devtest.txt').readlines()\n",
    "test = open('./data/Gold/test.txt').readlines()\n",
    "train = open('./data/Gold/train.txt').readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_gold_files(f):\n",
    "    res = []\n",
    "    for line in f:\n",
    "        s = line.split('\\t',2)\n",
    "        res.append((preprocess_tweet(s[2]),s[1]))\n",
    "    return res\n",
    "\n",
    "gold_tweets = read_gold_files(dev)+read_gold_files(devtest)+read_gold_files(test)+read_gold_files(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('jay z joins instagram nostalgic tribute michael jackson: jay z apparently joined instagram saturday and..',\n",
       "  'positive'),\n",
       " ('michael jackson: bad 25th anniversary edition (picture vinyl): unique picture disc vinyl includes original 1',\n",
       "  'neutral'),\n",
       " ('liked @youtube video one direction singing \"man mirror\" michael jackson atlanta, ga [june 26,\\n',\n",
       "  'positive'),\n",
       " (\"18th anniv princess diana's death. still want believe living private island away public. michael jackson.\\n\",\n",
       "  'positive'),\n",
       " ('@oridaganjazz 1st time heard michael jackson sing honolulu, hawaii @ restaurant radio. a.b.c. 13. loved it!\\n',\n",
       "  'positive'),\n",
       " (\"'michael jackson' appeared saturday 29 9th place top20 miami's trends: #trndnl\\n\",\n",
       "  'neutral'),\n",
       " ('old enough remember michael jackson attending grammys brooke shields webster sat lap show?\\n',\n",
       "  'positive'),\n",
       " (\"@etbowser u enjoy 2nd rate michael jackson bit? honest ques. like can't feel face song god obvious want mj 2.0\\n\",\n",
       "  'negative'),\n",
       " ('weeknd closest thing may get michael jackson long time...especially since damn near mimics everything\\n',\n",
       "  'neutral')]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gold_tweets[1:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num of tokens gold only: 27482\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda3/lib/python3.7/site-packages/IPython/core/pylabtools.py:128: UserWarning: Creating legend with loc=\"best\" can be slow with large amounts of data.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokens_tweet_url_punct_removed = white_tokens\n",
    "\n",
    "def remove_http(tweet):\n",
    "    t = tweet.split(' ')\n",
    "    temp = []\n",
    "    for s in t:\n",
    "        if \"https://\"  in s or \"http://\" in s or s.lower() in stop_words:\n",
    "            continue\n",
    "        else:\n",
    "            temp.append(s.lower())\n",
    "    return \" \".join(temp)\n",
    "\n",
    "def read_tweets(f):\n",
    "    positive = []\n",
    "    negative = []\n",
    "    neutral = []\n",
    "    tweets = []\n",
    "    res = []\n",
    "    for s in f:\n",
    "        t = s.split('\\t')\n",
    "        t[2] = remove_http(t[2])\n",
    "        if t[1] == \"positive\":\n",
    "            positive.append(t[2])\n",
    "        elif t[1] == \"negative\":\n",
    "            negative.append(t[2])\n",
    "        elif t[1] == \"neutral\":\n",
    "            neutral.append(t[2])\n",
    "        tweets.append(t[2])\n",
    "        res.append(t[1])\n",
    "    d = {}\n",
    "    d[\"positive\"] = positive\n",
    "    d[\"negative\"] = negative\n",
    "    d[\"neutral\"] = neutral\n",
    "    return tweets,d,res\n",
    "\n",
    "##dev_tweets, dev_tweets_dict,dev_res = read_tweets(dev)\n",
    "\n",
    "dev_tweets, dev_tweets_dict, dev_res = read_tweets(dev)\n",
    "devtest_tweets, devtest_tweets_dict, devtest_res = read_tweets(devtest)\n",
    "test_tweets, test_tweets_dict, test_res = read_tweets(test)\n",
    "train_tweets, train_tweets_dict, train_res = read_tweets(dev)\n",
    "\n",
    "#dev_tweets_dict['positive']\n",
    "\n",
    "tokens_dev_tweets = {}\n",
    "tokens_devtest_tweets = {}\n",
    "tokens_test_tweets = {}\n",
    "tokens_train_tweets = {}\n",
    "\n",
    "def process_list_tweets(tweets):\n",
    "    res = []\n",
    "    for tweet in tweets:\n",
    "        tokens = TweetTokenizer().tokenize(tweet)\n",
    "        tokens =  list(filter (lambda s:any([c.isalnum() for c in s]), tokens))\n",
    "        tokens = [x.lower() for x in tokens]\n",
    "        res.append(tokens)\n",
    "    return res\n",
    "\n",
    "tokens_dev_tweets['positive'] = process_list_tweets(dev_tweets_dict['positive'])\n",
    "tokens_dev_tweets['negative'] = process_list_tweets(dev_tweets_dict['negative'])\n",
    "tokens_dev_tweets['neutral'] = process_list_tweets(dev_tweets_dict['neutral'])\n",
    "\n",
    "tokens_devtest_tweets['positive'] = process_list_tweets(devtest_tweets_dict['positive'])\n",
    "tokens_devtest_tweets['negative'] = process_list_tweets(devtest_tweets_dict['negative'])\n",
    "tokens_devtest_tweets['neutral'] = process_list_tweets(devtest_tweets_dict['neutral'])\n",
    "\n",
    "tokens_test_tweets['positive'] = process_list_tweets(test_tweets_dict['positive'])\n",
    "tokens_test_tweets['negative'] = process_list_tweets(test_tweets_dict['negative'])\n",
    "tokens_test_tweets['neutral'] = process_list_tweets(test_tweets_dict['neutral'])\n",
    "\n",
    "tokens_train_tweets['positive'] = process_list_tweets(train_tweets_dict['positive'])\n",
    "tokens_train_tweets['negative'] = process_list_tweets(train_tweets_dict['negative'])\n",
    "tokens_train_tweets['neutral'] = process_list_tweets(train_tweets_dict['neutral'])\n",
    "\n",
    "\n",
    "tokens_gold_only = []\n",
    "for att in tokens_dev_tweets:\n",
    "    for tw in tokens_dev_tweets[att]:\n",
    "        for tok in tw:\n",
    "            if tok in tokens_gold_only or tok in tokens_tweet_url_punct_removed:\n",
    "                continue\n",
    "            else:\n",
    "                tokens_gold_only.append(tok)\n",
    "                \n",
    "\n",
    "len(tokens_gold_only)\n",
    "\n",
    "for att in tokens_devtest_tweets:\n",
    "    for tw in tokens_devtest_tweets[att]:\n",
    "        for tok in tw:\n",
    "            if tok in tokens_gold_only or tok in tokens_tweet_url_punct_removed:\n",
    "                continue\n",
    "            else:\n",
    "                tokens_gold_only.append(tok)\n",
    "                \n",
    "\n",
    "\n",
    "for att in tokens_test_tweets:\n",
    "    for tw in tokens_test_tweets[att]:\n",
    "        for tok in tw:\n",
    "            if tok in tokens_gold_only or tok in tokens_tweet_url_punct_removed:\n",
    "                continue\n",
    "            else:\n",
    "                tokens_gold_only.append(tok)\n",
    "\n",
    "\n",
    "\n",
    "for att in tokens_train_tweets:\n",
    "    for tw in tokens_train_tweets[att]:\n",
    "        for tok in tw:\n",
    "            if tok in tokens_gold_only or tok in tokens_tweet_url_punct_removed:\n",
    "                continue\n",
    "            else:\n",
    "                tokens_gold_only.append(tok)\n",
    "\n",
    "print(\"Num of tokens gold only:\",len(tokens_gold_only))\n",
    "\n",
    "\n",
    "\n",
    "positive_train = [item for sublist in tokens_train_tweets['positive'] for item in sublist]\n",
    "freq_post_train = FreqDist(positive_train)\n",
    "\n",
    "#freq_post_train.most_common(30)\n",
    "\n",
    "negative_train = [item for sublist in tokens_train_tweets['negative'] for item in sublist]\n",
    "freq_nega_train = FreqDist(negative_train)\n",
    "#freq_nega_train.most_common(30)\n",
    "\n",
    "neutral_train = [item for sublist in tokens_train_tweets['neutral'] for item in sublist]\n",
    "freq_neut_train = FreqDist(neutral_train)\n",
    "#freq_neut_train.most_common(30)\n",
    "\n",
    "##from 2-tools.ipynb\n",
    "def separate_tokens_types(words):\n",
    "\n",
    "    \"\"\"\n",
    "    Given a list of words from a corpus, separate the counts of tokens and\n",
    "    types in time. Return the two lists.\n",
    "    \"\"\"\n",
    "\n",
    "    t_d = {}\n",
    "    tokens, types = [], []\n",
    "    count = 0\n",
    "    for i in range(len(words)):\n",
    "\n",
    "        if words[i] not in t_d:\n",
    "            count += 1\n",
    "            t_d[words[i]] = 1\n",
    "\n",
    "        tokens.append(i + 1)\n",
    "        types.append(count)\n",
    "\n",
    "    return tokens, types\n",
    "\n",
    "gold_words = [t.split(' ') for t in dev_tweets]+[t.split(' ') for t in devtest_tweets]\n",
    "gold_words = gold_words+[t.split(' ') for t in test_tweets]+[t.split(' ') for t in train_tweets]\n",
    "gold_words = [item.lower() for sublist in gold_words for item in sublist if item.isalpha()]\n",
    "\n",
    "len(gold_words)\n",
    "\n",
    "gold_tokens, gold_types = separate_tokens_types(gold_words)\n",
    "\n",
    "plt.plot(gold_tokens, gold_types, label='Gold')\n",
    "\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "plt.title(\"Heaps' laws NLTK corpora\")\n",
    "plt.xlabel('Num tokens')\n",
    "plt.ylabel('Num types')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Positive:  9739\n",
      "Training Negative:  4338\n",
      "Training Neutral:  12553\n"
     ]
    }
   ],
   "source": [
    "print(\"Training Positive: \", len(tokens_train_tweets['positive'])+len(tokens_test_tweets['positive'])+len(tokens_dev_tweets['positive'])+len(tokens_devtest_tweets['positive']))\n",
    "print(\"Training Negative: \", len(tokens_train_tweets['negative'])+len(tokens_test_tweets['negative'])+len(tokens_dev_tweets['negative'])+len(tokens_devtest_tweets['negative']))\n",
    "print(\"Training Neutral: \", len(tokens_train_tweets['neutral'])+len(tokens_test_tweets['neutral'])+len(tokens_dev_tweets['neutral'])+len(tokens_devtest_tweets['neutral']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def features(tweet):\n",
    "    tokens = WhitespaceTokenizer().tokenize(tweet)\n",
    "    tokens = list(filter (lambda s:any([c.isalnum() for c in s]), tokens))\n",
    "    return dict(('contains(%s)' % w, True) for w in tokens)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "trains, tests = train_test_split(gold_tweets, test_size = 0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.classify import NaiveBayesClassifier\n",
    "from nltk.sentiment import SentimentAnalyzer\n",
    "from nltk.sentiment.util import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_features = [(features(tu[0]),tu[1]) for tu in trains]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22973"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(training_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training classifier\n"
     ]
    }
   ],
   "source": [
    "sentiment_analyzer = SentimentAnalyzer()\n",
    "trainer = NaiveBayesClassifier.train\n",
    "classifier = sentiment_analyzer.train(trainer, training_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "truth_list = [(features(tu[0]),tu[1]) for tu in tests]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating NaiveBayesClassifier results...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Accuracy': 0.5728649778009924,\n",
       " 'Precision [positive]': 0.6414746543778802,\n",
       " 'Recall [positive]': 0.6904761904761905,\n",
       " 'F-measure [positive]': 0.6650740563784042,\n",
       " 'Precision [neutral]': 0.6471095772217429,\n",
       " 'Recall [neutral]': 0.43770061278085787,\n",
       " 'F-measure [neutral]': 0.5221932114882506,\n",
       " 'Precision [negative]': 0.38321342925659474,\n",
       " 'Recall [negative]': 0.6619718309859155,\n",
       " 'F-measure [negative]': 0.48541919805589306}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_analyzer.evaluate(truth_list,classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk_vader_res = []\n",
    "\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "sentences = [t[0] for t in tests]\n",
    "for sentence in sentences:\n",
    "    vs = analyzer.polarity_scores(sentence)\n",
    "    if vs['compound'] >= 0.45 : \n",
    "        nltk_vader_res.append(\"positive\") \n",
    "    elif vs['compound'] <= - 0.45 : \n",
    "        nltk_vader_res.append(\"negative\") \n",
    "    else : \n",
    "        nltk_vader_res.append(\"neutral\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5629407155915382"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct = 0\n",
    "for i in range(len(sentences)):\n",
    "    if nltk_vader_res[i] == tests[i][1]: \n",
    "        correct = correct+1\n",
    "correct/len(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainingFeatures=nltk.classify.apply_features(features,trains)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "NBayesClassifier=nltk.NaiveBayesClassifier.train(trainingFeatures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "NBResultLabels = [NBayesClassifier.classify(tu[0]) for tu in truth_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb = 0\n",
    "for i in range(len(NBResultLabels)):\n",
    "    if NBResultLabels[i] == truth_list[i][1]:\n",
    "        nb = nb+1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_list = [features(t) for t in input_tweets]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_res = [NBayesClassifier.classify(t) for t in input_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('res.txt', 'w') as filehandle:\n",
    "    for listitem in input_res:\n",
    "        filehandle.write('%s\\n' % listitem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bigram_features(tweet):\n",
    "    grams = ngrams(tweet.lower().split(),2)\n",
    "    return dict(('contains(%s)' % \" \".join(w), True) for w in grams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_bigram_features = [(bigram_features(tu[0]),tu[1]) for tu in trains]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22973"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(training_bigram_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training classifier\n"
     ]
    }
   ],
   "source": [
    "trainer_bigram = NaiveBayesClassifier.train\n",
    "classifier_bigram = sentiment_analyzer.train(trainer_bigram, training_bigram_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "truth_list_bigram = [(bigram_features(tu[0]),tu[1]) for tu in tests]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating NaiveBayesClassifier results...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Accuracy': 0.5164533820840951,\n",
       " 'Precision [positive]': 0.5848303393213573,\n",
       " 'Recall [positive]': 0.5813492063492064,\n",
       " 'F-measure [positive]': 0.583084577114428,\n",
       " 'Precision [neutral]': 0.5533824943892273,\n",
       " 'Recall [neutral]': 0.5036475051065071,\n",
       " 'F-measure [neutral]': 0.5273449434769325,\n",
       " 'Precision [negative]': 0.30724070450097846,\n",
       " 'Recall [negative]': 0.39022369511184757,\n",
       " 'F-measure [negative]': 0.3437956204379562}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_analyzer.evaluate(truth_list_bigram,classifier_bigram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = []\n",
    "y_train = []\n",
    "for tu in trains:\n",
    "    x_train.append(tu[0])\n",
    "    if tu[1] == 'positive':\n",
    "        y_train.append(0)\n",
    "    elif tu[1] == 'negative':\n",
    "        y_train.append(2)\n",
    "    else:\n",
    "        y_train.append(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(lowercase=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<22973x32922 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 270026 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.fit(x_train)\n",
    "\n",
    "x_train_dtm = vectorizer.transform(x_train)\n",
    "\n",
    "x_train_dtm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<7658x32922 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 83046 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test = []\n",
    "y_test = []\n",
    "for tu in tests:\n",
    "    x_test.append(tu[0])\n",
    "    if tu[1] == 'positive':\n",
    "        y_test.append(0)\n",
    "    elif tu[1] == 'negative':\n",
    "        y_test.append(2)\n",
    "    else:\n",
    "        y_test.append(1)\n",
    "        \n",
    "\n",
    "x_test_dtm = vectorizer.transform(x_test)\n",
    "\n",
    "x_test_dtm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='warn', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg.fit(x_train_dtm, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_prediction_class = logreg.predict(x_test_dtm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    positive       0.66      0.68      0.67      3024\n",
      "     neutral       0.60      0.67      0.64      3427\n",
      "    negative       0.60      0.36      0.45      1207\n",
      "\n",
      "    accuracy                           0.62      7658\n",
      "   macro avg       0.62      0.57      0.58      7658\n",
      "weighted avg       0.62      0.62      0.62      7658\n",
      "\n"
     ]
    }
   ],
   "source": [
    "target_names = ['positive', 'neutral', 'negative']\n",
    "score = metrics.precision_recall_fscore_support(y_true=y_test, y_pred=y_prediction_class)\n",
    "print(classification_report(y_true=y_test, y_pred=y_prediction_class, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<12284x32922 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 94641 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_log = input_tweets\n",
    "input_log_dtm = vectorizer.transform(input_log)\n",
    "input_log_dtm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_predict = logreg.predict(input_log_dtm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_predict_res = []\n",
    "for p in input_predict:\n",
    "    if p == 1:\n",
    "        input_predict_res.append('neutral')\n",
    "    elif p == 0:\n",
    "        input_predict_res.append('positive')\n",
    "    else:\n",
    "        input_predict_res.append('negative')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_vader_res = []\n",
    "\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "sentences = input_tweets\n",
    "for sentence in sentences:\n",
    "    vs = analyzer.polarity_scores(sentence)\n",
    "    if vs['compound'] >= 0.45 : \n",
    "        input_vader_res.append(\"positive\") \n",
    "    elif vs['compound'] <= - 0.45 : \n",
    "        input_vader_res.append(\"negative\") \n",
    "    else : \n",
    "        input_vader_res.append(\"neutral\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_ids = [tu[0] for tu in input_tuple]\n",
    "df = pd.DataFrame(list(zip(tweet_ids, input_res, input_predict_res, input_vader_res)), \n",
    "               columns =['id', 'NB', 'LR', 'VD']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>NB</th>\n",
       "      <th>LR</th>\n",
       "      <th>VD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>801989080477154944</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>801989272341453952</td>\n",
       "      <td>positive</td>\n",
       "      <td>positive</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>801990978424962944</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>801996232553963008</td>\n",
       "      <td>positive</td>\n",
       "      <td>positive</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>801998343442407040</td>\n",
       "      <td>positive</td>\n",
       "      <td>positive</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   id        NB        LR        VD\n",
       "0  801989080477154944   neutral   neutral   neutral\n",
       "1  801989272341453952  positive  positive  positive\n",
       "2  801990978424962944   neutral   neutral   neutral\n",
       "3  801996232553963008  positive  positive  positive\n",
       "4  801998343442407040  positive  positive   neutral"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('res.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
